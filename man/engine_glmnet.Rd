% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/engine_glmnet.R
\name{engine_glmnet}
\alias{engine_glmnet}
\title{Engine for regularized regression models}
\usage{
engine_glmnet(
  x,
  alpha = 0,
  nlambda = 100,
  lambda = NULL,
  type = "response",
  ...
)
}
\arguments{
\item{x}{\code{\link[=distribution]{distribution()}} (i.e. \code{\linkS4class{BiodiversityDistribution}}) object.}

\item{alpha}{A \code{\link{numeric}} giving the elasticnet mixing parameter, which has
to be between \code{0} and \code{1}. \code{alpha=1} is the lasso penalty,
and \code{alpha=0} the ridge penalty (Default: \code{0}).}

\item{nlambda}{A \code{\link{numeric}} giving the number of lambda values to be used (Default: \code{100}).}

\item{lambda}{A \code{\link{numeric}} with a user supplied estimate of lambda. Usually
best to let this parameter be determined deterministically (Default: \code{NULL}).}

\item{type}{The mode used for creating posterior predictions. Either making
\code{"link"} or \code{"response"} (Default: \code{"response"}).}

\item{...}{Other parameters passed on to glmnet.}
}
\value{
An \link{Engine}.
}
\description{
This engine allows the estimation of linear coefficients using
either ridge, lasso or elastic net regressions techniques. Backbone of this
engine is the \pkg{glmnet} R-package which is commonly used in SDMs,
including the popular \code{'maxnet'} (e.g. Maxent) package. Ultimately this
engine is an equivalent of \link{engine_breg}, but in a "frequentist" setting. If
user aim to emulate a model that most closely resembles maxent within the
ibis.iSDM modelling framework, then this package is the best way of doing so.
Compared to the \code{'maxnet'} R-package, a number of efficiency settings
are implemented in particular for cross-validation of alpha and lambda
values.

Limited amount of prior information can be specified for this engine,
specifically via offsets or as \code{\link{GLMNETPrior}}, which allow to specify priors
as regularization constants.
}
\details{
Regularized regressions are effectively GLMs that are fitted with
ridge, lasso or elastic-net regularization. Which of them is chosen is
critical dependent on the alpha value: \link{*} For \code{alpha} equal to \code{0}
a ridge regularization is used. Ridge regularization has the property that it
doesn't remove variables entirely, but instead sets their coefficients to
\code{0}. \link{*} For \code{alpha} equal to \code{1} a lasso regularization is
used. Lassos tend to remove those coefficients fully from the final model
that do not improve the loss function. \link{*} For \code{alpha} values between
\code{0} and \code{1} a elastic-net regularization is used, which is
essentially a combination of the two. The optimal lambda parameter can be
determined via cross-validation. For this option set \code{"varsel"} in
\code{train()} to \code{"reg"}.
}
\examples{
\dontrun{
# Add GLMNET as an engine
x <- distribution(background) |> engine_glmnet(iter = 1000)
}

}
\references{
\itemize{
\item Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization Paths
for Generalized Linear Models via Coordinate Descent. Journal of Statistical Software,
33(1), 1-22. URL https://www.jstatsoft.org/v33/i01/.
\item Renner, I.W., Elith, J., Baddeley, A., Fithian, W., Hastie, T., Phillips, S.J.,
Popovic, G. and Warton, D.I., 2015. Point process models for presence‐only analysis.
Methods in Ecology and Evolution, 6(4), pp.366-379.
\item Fithian, W. & Hastie, T. (2013) Finite-sample equivalence in statistical models
for presence-only data. The Annals of Applied Statistics 7, 1917–1939
}
}
\seealso{
Other engine: 
\code{\link{engine_bart}()},
\code{\link{engine_breg}()},
\code{\link{engine_gdb}()},
\code{\link{engine_glm}()},
\code{\link{engine_inla}()},
\code{\link{engine_inlabru}()},
\code{\link{engine_scampr}()},
\code{\link{engine_stan}()},
\code{\link{engine_xgboost}()}
}
\concept{engine}
